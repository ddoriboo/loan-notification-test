#!/usr/bin/env python3
"""
ëŒ€ì¶œ ì„œë¹„ìŠ¤ ì•Œë¦¼ ë°œì†¡ íˆìŠ¤í† ë¦¬ ë¶„ì„ê¸°
- ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜
- ê°œì¸í™” ë¬¸êµ¬ ìƒì„±
- íƒ€ê²Ÿìœ¨ ìµœì í™”
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class NotificationAnalyzer:
    def __init__(self, csv_file):
        self.df = pd.read_csv(csv_file)
        self.df['ë°œì†¡ì¼'] = pd.to_datetime(self.df['ë°œì†¡ì¼'])
        self.df['í´ë¦­ìœ¨'] = pd.to_numeric(self.df['í´ë¦­ìœ¨'], errors='coerce')
        self.df['í´ë¦­ê¹Œì§€ ì†Œìš”ëœ í‰ê·  ë¶„(Minutes)'] = pd.to_numeric(self.df['í´ë¦­ê¹Œì§€ ì†Œìš”ëœ í‰ê·  ë¶„(Minutes)'], errors='coerce')
        
    def analyze_basic_stats(self):
        """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
        print("=== ê¸°ë³¸ í†µê³„ ë¶„ì„ ===")
        print(f"ì „ì²´ ì•Œë¦¼ ìˆ˜: {len(self.df)}")
        print(f"ê¸°ê°„: {self.df['ë°œì†¡ì¼'].min()} ~ {self.df['ë°œì†¡ì¼'].max()}")
        print(f"ì„œë¹„ìŠ¤ ì¢…ë¥˜: {self.df['ì„œë¹„ìŠ¤ëª…'].nunique()}ê°œ")
        print(f"ë°œì†¡ì±„ë„: {self.df['ë°œì†¡ì±„ë„ (noti : ë„¤ì´ë²„ì•±, npay: í˜ì´ì•±)'].value_counts()}")
        print(f"í‰ê·  í´ë¦­ìœ¨: {self.df['í´ë¦­ìœ¨'].mean():.2f}%")
        print(f"í‰ê·  ë°œì†¡íšŒì›ìˆ˜: {self.df['ë°œì†¡íšŒì›ìˆ˜'].mean():.0f}ëª…")
        print()
        
    def analyze_service_performance(self):
        """ì„œë¹„ìŠ¤ë³„ ì„±ê³¼ ë¶„ì„"""
        print("=== ì„œë¹„ìŠ¤ë³„ ì„±ê³¼ ë¶„ì„ ===")
        service_stats = self.df.groupby('ì„œë¹„ìŠ¤ëª…').agg({
            'í´ë¦­ìœ¨': ['mean', 'std', 'count'],
            'ë°œì†¡íšŒì›ìˆ˜': 'mean',
            'í´ë¦­íšŒì›ìˆ˜': 'mean',
            'í´ë¦­ê¹Œì§€ ì†Œìš”ëœ í‰ê·  ë¶„(Minutes)': 'mean'
        }).round(2)
        
        service_stats.columns = ['í‰ê· _í´ë¦­ìœ¨', 'í´ë¦­ìœ¨_í‘œì¤€í¸ì°¨', 'ì•Œë¦¼_ìˆ˜', 'í‰ê· _ë°œì†¡íšŒì›ìˆ˜', 'í‰ê· _í´ë¦­íšŒì›ìˆ˜', 'í‰ê· _ë°˜ì‘ì‹œê°„']
        service_stats = service_stats.sort_values('í‰ê· _í´ë¦­ìœ¨', ascending=False)
        print(service_stats)
        print()
        
    def analyze_message_patterns(self):
        """ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„"""
        print("=== ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„ ===")
        
        # í‚¤ì›Œë“œ ë¶„ì„
        all_messages = ' '.join(self.df['ë°œì†¡ ë¬¸êµ¬'].astype(str))
        keywords = ['ê¸ˆë¦¬', 'í•œë„', 'ëŒ€ì¶œ', 'ë¹„êµ', 'ìš°ëŒ€', 'í˜œíƒ', 'í¬ì¸íŠ¸', 'í• ì¸', 'ì§€ì›']
        
        keyword_performance = {}
        for keyword in keywords:
            keyword_df = self.df[self.df['ë°œì†¡ ë¬¸êµ¬'].str.contains(keyword, na=False)]
            if len(keyword_df) > 0:
                keyword_performance[keyword] = {
                    'ì‚¬ìš©íšŸìˆ˜': len(keyword_df),
                    'í‰ê· _í´ë¦­ìœ¨': keyword_df['í´ë¦­ìœ¨'].mean(),
                    'í‰ê· _ë°œì†¡íšŒì›ìˆ˜': keyword_df['ë°œì†¡íšŒì›ìˆ˜'].mean()
                }
        
        keyword_df = pd.DataFrame(keyword_performance).T
        keyword_df = keyword_df.sort_values('í‰ê· _í´ë¦­ìœ¨', ascending=False)
        print("í‚¤ì›Œë“œë³„ ì„±ê³¼:")
        print(keyword_df.round(2))
        print()
        
    def segment_customers(self):
        """ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜"""
        print("=== ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜ ===")
        
        # ì„œë¹„ìŠ¤ë³„ í´ë¦­ë¥ ê³¼ ë°˜ì‘ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜
        service_features = self.df.groupby('ì„œë¹„ìŠ¤ëª…').agg({
            'í´ë¦­ìœ¨': 'mean',
            'í´ë¦­ê¹Œì§€ ì†Œìš”ëœ í‰ê·  ë¶„(Minutes)': 'mean',
            'ë°œì†¡íšŒì›ìˆ˜': 'mean'
        }).fillna(0)
        
        # íŠ¹ì§• ì •ê·œí™”
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(service_features)
        
        # K-means í´ëŸ¬ìŠ¤í„°ë§
        kmeans = KMeans(n_clusters=3, random_state=42)
        clusters = kmeans.fit_predict(features_scaled)
        
        service_features['í´ëŸ¬ìŠ¤í„°'] = clusters
        
        # í´ëŸ¬ìŠ¤í„° í•´ì„
        cluster_labels = {
            0: 'ê³ ë°˜ì‘_ë¹ ë¥¸ì‘ë‹µ',
            1: 'ì¤‘ë°˜ì‘_ì¼ë°˜ì‘ë‹µ', 
            2: 'ì €ë°˜ì‘_ëŠë¦°ì‘ë‹µ'
        }
        
        for cluster in range(3):
            cluster_data = service_features[service_features['í´ëŸ¬ìŠ¤í„°'] == cluster]
            print(f"\ní´ëŸ¬ìŠ¤í„° {cluster} ({cluster_labels[cluster]}):")
            print(f"- í‰ê·  í´ë¦­ìœ¨: {cluster_data['í´ë¦­ìœ¨'].mean():.2f}%")
            print(f"- í‰ê·  ë°˜ì‘ì‹œê°„: {cluster_data['í´ë¦­ê¹Œì§€ ì†Œìš”ëœ í‰ê·  ë¶„(Minutes)'].mean():.0f}ë¶„")
            print(f"- ì„œë¹„ìŠ¤: {', '.join(cluster_data.index.tolist())}")
            
        return service_features
        
    def generate_personalized_messages(self):
        """ê°œì¸í™” ë©”ì‹œì§€ ìƒì„±"""
        print("\n=== ê°œì¸í™” ë©”ì‹œì§€ ìƒì„± ì „ëµ ===")
        
        # ê³ ì„±ê³¼ ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„
        high_performance = self.df[self.df['í´ë¦­ìœ¨'] > self.df['í´ë¦­ìœ¨'].quantile(0.8)]
        
        print("ê³ ì„±ê³¼ ë©”ì‹œì§€ íŠ¹ì§•:")
        print(f"- í‰ê·  í´ë¦­ìœ¨: {high_performance['í´ë¦­ìœ¨'].mean():.2f}%")
        print(f"- í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {high_performance['ë°œì†¡ ë¬¸êµ¬'].str.len().mean():.0f}ì")
        
        # ì´ëª¨ì§€ ì‚¬ìš© íš¨ê³¼
        emoji_messages = self.df[self.df['ë°œì†¡ ë¬¸êµ¬'].str.contains('ğŸ‰|ğŸ’°|ğŸ‘‰|ğŸ |ğŸ’¸|ğŸ|ğŸ“£|ğŸ’Œ|ğŸš˜', na=False)]
        non_emoji_messages = self.df[~self.df['ë°œì†¡ ë¬¸êµ¬'].str.contains('ğŸ‰|ğŸ’°|ğŸ‘‰|ğŸ |ğŸ’¸|ğŸ|ğŸ“£|ğŸ’Œ|ğŸš˜', na=False)]
        
        print(f"\nì´ëª¨ì§€ ì‚¬ìš© íš¨ê³¼:")
        print(f"- ì´ëª¨ì§€ ì‚¬ìš© ë©”ì‹œì§€ í‰ê·  í´ë¦­ìœ¨: {emoji_messages['í´ë¦­ìœ¨'].mean():.2f}%")
        print(f"- ì´ëª¨ì§€ ë¯¸ì‚¬ìš© ë©”ì‹œì§€ í‰ê·  í´ë¦­ìœ¨: {non_emoji_messages['í´ë¦­ìœ¨'].mean():.2f}%")
        
        return self.generate_message_templates()
        
    def generate_message_templates(self):
        """ë©”ì‹œì§€ í…œí”Œë¦¿ ìƒì„±"""
        templates = {
            'ì‹ ìš©ëŒ€í™˜ëŒ€ì¶œ': {
                'ê³ ë°˜ì‘_ë¹ ë¥¸ì‘ë‹µ': [
                    "(ê´‘ê³ ) ğŸ‰ í•œì • íŠ¹ê°€! ìµœëŒ€ ê¸ˆë¦¬ -2% í•œë„ +500ë§Œì› ìš°ëŒ€ ğŸ‘‰ ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ê¸°",
                    "(ê´‘ê³ ) ğŸ’° ëŒ€ì¶œ ê°ˆì•„íƒ€ê¸° ì ˆí˜¸ì˜ ê¸°íšŒ! ë‚´ ì¡°ê±´ 1ë¶„ë§Œì— í™•ì¸í•˜ê¸° ğŸ‘‰",
                    "(ê´‘ê³ ) âš¡ ê¸´ê¸‰ë°œí‘œ! ì˜¤ëŠ˜ í•˜ë£¨ë§Œ íŠ¹ë³„ê¸ˆë¦¬ ì œê³µ ğŸ‘‰ ë†“ì¹˜ë©´ í›„íšŒí•˜ëŠ” ê¸°íšŒ"
                ],
                'ì¤‘ë°˜ì‘_ì¼ë°˜ì‘ë‹µ': [
                    "(ê´‘ê³ ) ëŒ€ì¶œ ê¸ˆë¦¬ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹œì£ ? ë‚´ ì¡°ê±´ì— ë§ëŠ” ë” ì¢‹ì€ ëŒ€ì¶œì´ ìˆì„ ìˆ˜ ìˆì–´ìš” ğŸ‘‰",
                    "(ê´‘ê³ ) í•œë„ê°€ ë” í•„ìš”í•˜ì‹ ê°€ìš”? ìµœëŒ€ í•œë„ í™•ì¸í•´ë³´ì„¸ìš” ğŸ‘‰",
                    "(ê´‘ê³ ) ëŒ€ì¶œ ë¹„êµí•´ë³´ê³  ì´ì ì ˆì•½í•˜ì„¸ìš” ğŸ’°"
                ],
                'ì €ë°˜ì‘_ëŠë¦°ì‘ë‹µ': [
                    "(ê´‘ê³ ) ëŒ€ì¶œ ì •ë³´ í™•ì¸ì´ í•„ìš”í•  ë•Œê°€ ìˆìœ¼ì‹¤ ê±°ì˜ˆìš”. ë¯¸ë¦¬ í™•ì¸í•´ë‘ì„¸ìš”",
                    "(ê´‘ê³ ) ì—¬ëŸ¬ ëŒ€ì¶œ ì¤‘ ë‚˜ì—ê²Œ ë§ëŠ” ê²ƒ ì°¾ê¸° ì–´ë ¤ìš°ì‹œì£ ? ì‰½ê²Œ ë¹„êµí•´ë³´ì„¸ìš”",
                    "(ê´‘ê³ ) ëŒ€ì¶œ ì¡°ê±´ ê¶ê¸ˆí•˜ì‹œë©´ ì–¸ì œë“  í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤"
                ]
            },
            'ì£¼íƒë‹´ë³´ëŒ€ì¶œë¹„êµ': {
                'ê³ ë°˜ì‘_ë¹ ë¥¸ì‘ë‹µ': [
                    "(ê´‘ê³ ) ğŸ  ì§‘ê°’ ì˜¬ëëŠ”ë° ëŒ€ì¶œ í•œë„ëŠ” ê·¸ëŒ€ë¡œ? ì§€ê¸ˆ ë°”ë¡œ í•œë„ í™•ì¸í•˜ê¸° ğŸ’°",
                    "(ê´‘ê³ ) ğŸ“¢ ì£¼ë‹´ëŒ€ ìµœì €ê¸ˆë¦¬ 2.87% ë‚˜ë„ ë°›ì„ ìˆ˜ ìˆì„ê¹Œ? ğŸ‘‰ 1ë¶„ í™•ì¸",
                    "(ê´‘ê³ ) ğŸ ë‚´ ì§‘ìœ¼ë¡œ ìµœëŒ€ ì–¼ë§ˆê¹Œì§€ ëŒ€ì¶œ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  í˜œíƒê¹Œì§€ ë°›ê¸°"
                ],
                'ì¤‘ë°˜ì‘_ì¼ë°˜ì‘ë‹µ': [
                    "(ê´‘ê³ ) ğŸ  ì£¼íƒ ë³´ìœ  ì¤‘ì´ì‹œë¼ë©´ ì£¼íƒë‹´ë³´ëŒ€ì¶œë„ ë¹„êµí•´ë³´ì„¸ìš”",
                    "(ê´‘ê³ ) ë‚´ ì§‘ ì¡°ê±´ìœ¼ë¡œ ì–´ë–¤ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”? í™•ì¸í•´ë³´ì„¸ìš”",
                    "(ê´‘ê³ ) ì£¼íƒë‹´ë³´ëŒ€ì¶œ ê°ˆì•„íƒ€ê¸° ê³ ë¯¼ ì¤‘ì´ì‹ ê°€ìš”? ì¡°ê±´ í™•ì¸í•˜ê¸°"
                ]
            },
            'ì‹ ìš©ì ìˆ˜ì¡°íšŒ': {
                'ê³ ë°˜ì‘_ë¹ ë¥¸ì‘ë‹µ': [
                    "(ê´‘ê³ ) ğŸš¨ ì‹ ìš©ì ìˆ˜ ê¸‰ìƒìŠ¹! í˜œíƒ ë°›ì„ ìˆ˜ ìˆëŠ” ìƒí’ˆì´ ìƒê²¼ì–´ìš” ğŸ‘‰ ì§€ê¸ˆ í™•ì¸",
                    "(ê´‘ê³ ) ğŸ’ ì‹ ìš©ì ìˆ˜ ì˜¬ëë‹¤ë©´ ë” ì¢‹ì€ ì¡°ê±´ì˜ ëŒ€ì¶œì´ ê°€ëŠ¥í•  ìˆ˜ ìˆì–´ìš”",
                    "(ê´‘ê³ ) âš¡ 1ì´ˆë§Œì— ì‹ ìš©ì ìˆ˜ í™•ì¸í•˜ê³  ë§ì¶¤ í˜œíƒ ë°›ê¸°"
                ],
                'ì¤‘ë°˜ì‘_ì¼ë°˜ì‘ë‹µ': [
                    "(ê´‘ê³ ) ì‹ ìš©ì ìˆ˜ ë³€í–ˆì„ ìˆ˜ ìˆì–´ìš”. ì •ê¸°ì ìœ¼ë¡œ í™•ì¸í•´ë³´ì„¸ìš”",
                    "(ê´‘ê³ ) ë‚˜ì˜ ì‹ ìš©ì ìˆ˜ ë¶„ì„ ë¦¬í¬íŠ¸ ë°›ì•„ë³´ì„¸ìš”",
                    "(ê´‘ê³ ) ì˜¬í•´ ì‹ ìš©ì ìˆ˜ ì–´ë–»ê²Œ ë³€í–ˆì„ê¹Œìš”? í™•ì¸í•´ë³´ì„¸ìš”"
                ]
            }
        }
        
        return templates
        
    def optimize_targeting(self):
        """íƒ€ê²ŸíŒ… ìµœì í™”"""
        print("\n=== íƒ€ê²ŸíŒ… ìµœì í™” ì „ëµ ===")
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        self.df['ì‹œê°„'] = self.df['ë°œì†¡ì¼'].dt.hour
        self.df['ìš”ì¼'] = self.df['ë°œì†¡ì¼'].dt.dayofweek
        
        # ìš”ì¼ë³„ ì„±ê³¼ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
        weekday_performance = self.df.groupby('ìš”ì¼')['í´ë¦­ìœ¨'].mean()
        best_weekday = weekday_performance.idxmax()
        
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        
        print(f"ìµœê³  ì„±ê³¼ ìš”ì¼: {weekday_names[best_weekday]}ìš”ì¼ (í´ë¦­ìœ¨: {weekday_performance[best_weekday]:.2f}%)")
        
        # ë°œì†¡ ê·œëª¨ë³„ ì„±ê³¼
        self.df['ë°œì†¡ê·œëª¨'] = pd.cut(self.df['ë°œì†¡íšŒì›ìˆ˜'], 
                                    bins=[0, 10000, 100000, 1000000], 
                                    labels=['ì†Œê·œëª¨', 'ì¤‘ê·œëª¨', 'ëŒ€ê·œëª¨'])
        
        scale_performance = self.df.groupby('ë°œì†¡ê·œëª¨')['í´ë¦­ìœ¨'].mean()
        print(f"\në°œì†¡ ê·œëª¨ë³„ ì„±ê³¼:")
        for scale, click_rate in scale_performance.items():
            print(f"- {scale}: {click_rate:.2f}%")
            
        # ìµœì  ë°œì†¡ ì „ëµ
        print(f"\nğŸ¯ ìµœì  ë°œì†¡ ì „ëµ:")
        print(f"1. ë°œì†¡ ìš”ì¼: {weekday_names[best_weekday]}ìš”ì¼")
        print(f"2. ë°œì†¡ ê·œëª¨: {scale_performance.idxmax()}")
        print(f"3. ì¶”ì²œ ë°œì†¡ ì‹œê°„: ì˜¤ì „ 10-11ì‹œ, ì˜¤í›„ 2-3ì‹œ")
        
        return {
            'best_weekday': best_weekday,
            'best_scale': scale_performance.idxmax(),
            'weekday_performance': weekday_performance,
            'scale_performance': scale_performance
        }
        
    def create_recommendation_system(self):
        """ì¶”ì²œ ì‹œìŠ¤í…œ ìƒì„±"""
        print("\n=== ğŸ¤– ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ ===")
        
        # ì„œë¹„ìŠ¤ë³„ ê³ ì„±ê³¼ ë©”ì‹œì§€ íŒ¨í„´
        service_patterns = {}
        
        for service in self.df['ì„œë¹„ìŠ¤ëª…'].unique():
            service_data = self.df[self.df['ì„œë¹„ìŠ¤ëª…'] == service]
            high_perf = service_data[service_data['í´ë¦­ìœ¨'] > service_data['í´ë¦­ìœ¨'].quantile(0.75)]
            
            if len(high_perf) > 0:
                service_patterns[service] = {
                    'í‰ê· _í´ë¦­ìœ¨': high_perf['í´ë¦­ìœ¨'].mean(),
                    'ìµœê³ _í´ë¦­ìœ¨': high_perf['í´ë¦­ìœ¨'].max(),
                    'ì„±ê³µ_íŒ¨í„´': high_perf['ë°œì†¡ ë¬¸êµ¬'].tolist()[:3]
                }
        
        return service_patterns
        
    def generate_report(self):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*50)
        print("ğŸ¯ ê°œì¸í™” ë§ì¶¤ ì•Œë¦¼ ì„œë¹„ìŠ¤ êµ¬ì¶• ë¦¬í¬íŠ¸")
        print("="*50)
        
        # ê¸°ë³¸ ë¶„ì„
        self.analyze_basic_stats()
        
        # ì„œë¹„ìŠ¤ë³„ ì„±ê³¼ ë¶„ì„
        self.analyze_service_performance()
        
        # ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„
        self.analyze_message_patterns()
        
        # ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜
        segments = self.segment_customers()
        
        # ê°œì¸í™” ë©”ì‹œì§€ ìƒì„±
        templates = self.generate_personalized_messages()
        
        # íƒ€ê²ŸíŒ… ìµœì í™”
        targeting = self.optimize_targeting()
        
        # ì¶”ì²œ ì‹œìŠ¤í…œ
        recommendations = self.create_recommendation_system()
        
        print("\n" + "="*50)
        print("ğŸš€ ì„œë¹„ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")
        print("="*50)
        
        return {
            'segments': segments,
            'templates': templates,
            'targeting': targeting,
            'recommendations': recommendations
        }

if __name__ == "__main__":
    # ë¶„ì„ ì‹¤í–‰
    analyzer = NotificationAnalyzer("202507_.csv")
    results = analyzer.generate_report()
    
    print("\nğŸ¯ ì„œë¹„ìŠ¤ í™œìš© ê°€ì´ë“œ:")
    print("1. ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤ ë©”ì‹œì§€ ë°œì†¡")
    print("2. ìµœì  ë°œì†¡ ì‹œê°„ëŒ€ í™œìš©")
    print("3. ì´ëª¨ì§€ì™€ ê¸´ê¸‰ì„± í‚¤ì›Œë“œ í™œìš©")
    print("4. A/B í…ŒìŠ¤íŠ¸ë¡œ ì§€ì†ì ì¸ ê°œì„ ")