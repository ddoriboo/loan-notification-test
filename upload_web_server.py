#!/usr/bin/env python3
"""
CSV ì—…ë¡œë“œ ê¸°ë°˜ ì›¹ ì„œë²„
- íŒŒì¼ ì˜ì¡´ì„± ì—†ëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ ì²˜ë¦¬
- ì‚¬ìš©ìê°€ ì§ì ‘ CSV ì—…ë¡œë“œ
- ì•ˆì •ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
"""

import http.server
import socketserver
import json
import urllib.parse
import os
from upload_analyzer import analyzer

# OpenAI ì„¤ì •
try:
    import openai
    OPENAI_AVAILABLE = True
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    api_key = os.environ.get('OPENAI_API_KEY')
    if api_key:
        openai.api_key = api_key
        print("âœ… OpenAI API ì„¤ì • ì™„ë£Œ")
    else:
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        OPENAI_AVAILABLE = False
        
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")

class UploadHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        if self.path == '/':
            self.serve_main_page()
        else:
            return super().do_GET()
    
    def serve_main_page(self):
        """ë©”ì¸ í˜ì´ì§€ ì§ì ‘ ì„œë¹™"""
        try:
            with open('upload_web_interface.html', 'r', encoding='utf-8') as f:
                content = f.read()
            
            self.send_response(200)
            self.send_header('Content-Type', 'text/html; charset=utf-8')
            self.send_header('Content-Length', str(len(content.encode('utf-8'))))
            self.end_headers()
            
            self.wfile.write(content.encode('utf-8'))
            
        except FileNotFoundError:
            self.send_error(404, "Main page not found")
        except Exception as e:
            print(f"âŒ ë©”ì¸ í˜ì´ì§€ ì„œë¹™ ì‹¤íŒ¨: {e}")
            self.send_error(500, "Internal server error")
    
    def do_POST(self):
        if self.path == '/api/upload-csv':
            self.handle_upload_csv()
        elif self.path == '/api/dashboard':
            self.handle_dashboard()
        elif self.path == '/api/generate':
            self.handle_generate()
        else:
            self.send_error(404)
    
    def handle_upload_csv(self):
        """CSV ì—…ë¡œë“œ ë° ë¶„ì„ ì²˜ë¦¬"""
        try:
            print("ğŸ“Š CSV ì—…ë¡œë“œ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘...")
            
            # POST ë°ì´í„° ì½ê¸°
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            csv_content = data.get('csv_content', '')
            if not csv_content:
                raise ValueError("CSV ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ“„ CSV í¬ê¸°: {len(csv_content)} ë¬¸ì")
            
            # CSV ë¶„ì„ ìˆ˜í–‰
            result = analyzer.analyze_uploaded_csv(csv_content)
            
            if result['success']:
                print(f"âœ… CSV ë¶„ì„ ì„±ê³µ: {result['total_messages']}ê°œ ë©”ì‹œì§€")
            else:
                print(f"âŒ CSV ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
            
            self.send_json_response(result)
            
        except Exception as e:
            print(f"âŒ CSV ì—…ë¡œë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            
            error_response = {
                'success': False,
                'error': f"CSV ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            }
            self.send_json_response(error_response, status=500)
    
    def handle_dashboard(self):
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë°˜í™˜"""
        try:
            print("ğŸ“Š ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìš”ì²­...")
            
            # ë¶„ì„ê¸°ì—ì„œ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            dashboard_data = analyzer.get_dashboard_data()
            
            if dashboard_data['success']:
                print("âœ… ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì „ì†¡ ì™„ë£Œ")
            else:
                print(f"âš ï¸ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì—†ìŒ: {dashboard_data['error']}")
            
            self.send_json_response(dashboard_data)
            
        except Exception as e:
            print(f"âŒ ëŒ€ì‹œë³´ë“œ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            error_response = {
                'success': False,
                'error': f"ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}"
            }
            self.send_json_response(error_response, status=500)
    
    def handle_generate(self):
        """AI ë¬¸êµ¬ ìƒì„± ì²˜ë¦¬"""
        try:
            print("âœ¨ AI ë¬¸êµ¬ ìƒì„± ìš”ì²­...")
            
            # ë¶„ì„ ì™„ë£Œ í™•ì¸
            if not analyzer.analysis_complete:
                raise ValueError("ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
            
            # POST ë°ì´í„° ì½ê¸°
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            print(f"ğŸ“ ìƒì„± ìš”ì²­: {data}")
            
            # ìš”ì²­ ë°ì´í„° êµ¬ì„±
            user_request = {
                'description': data.get('description', ''),
                'service': data.get('service', ''),
                'target_audience': data.get('target_audience', 'ê³ ê°'),
                'tone': data.get('tone', 'promotional')
            }
            
            # AI ë¬¸êµ¬ ìƒì„±
            if OPENAI_AVAILABLE and openai.api_key:
                generated_messages = self.generate_with_openai(user_request)
            else:
                generated_messages = self.generate_simulation(user_request)
            
            # ê´€ë ¨ ê¸°ì¡´ ë©”ì‹œì§€ ì°¾ê¸°
            relevant_messages = self.find_relevant_messages(user_request)
            
            # ì‘ë‹µ êµ¬ì„±
            response = {
                'success': True,
                'generated_messages': generated_messages,
                'relevant_existing_messages': relevant_messages,
                'data_insights': {
                    'total_analyzed': len(analyzer.data),
                    'high_performance_count': len(analyzer.high_performance_messages),
                    'average_click_rate': analyzer.performance_patterns.get('overall_avg', 0)
                }
            }
            
            print("âœ… AI ë¬¸êµ¬ ìƒì„± ì™„ë£Œ")
            self.send_json_response(response)
            
        except Exception as e:
            print(f"âŒ AI ë¬¸êµ¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            
            error_response = {
                'success': False,
                'error': f"ë¬¸êµ¬ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            }
            self.send_json_response(error_response, status=500)
    
    def generate_with_openai(self, user_request):
        """OpenAIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ AI ë¬¸êµ¬ ìƒì„±"""
        try:
            print("ğŸ¤– OpenAI GPT-4oë¡œ ë¬¸êµ¬ ìƒì„± ì¤‘...")
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_generation_prompt(user_request)
            
            # OpenAI API í˜¸ì¶œ
            client = openai.OpenAI(api_key=openai.api_key)
            response = client.chat.completions.create(
                model="gpt-4o-2024-11-20",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ê¸°ë°˜ì˜ ì „ë¬¸ ë§ˆì¼€íŒ… ë¬¸êµ¬ ì‘ì„±ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            llm_response = response.choices[0].message.content
            print("âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            
            # ì‘ë‹µ íŒŒì‹±
            return self.parse_llm_response(llm_response)
            
        except Exception as e:
            print(f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ì‹œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ fallback
            return self.generate_simulation(user_request)
    
    def generate_simulation(self, user_request):
        """ì‹œë®¬ë ˆì´ì…˜ ë¬¸êµ¬ ìƒì„± (OpenAI ì—†ì„ ë•Œ)"""
        print("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë¬¸êµ¬ ìƒì„±...")
        
        description = user_request.get('description', '')
        service = user_request.get('service', 'ëŒ€ì¶œ')
        target = user_request.get('target_audience', 'ê³ ê°')
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        keyword_list = ['í˜œíƒ', 'ìµœëŒ€', 'í• ì¸', 'ê¸ˆë¦¬', 'í•œë„', 'ëŒ€ì¶œ', 'ë¹„êµ', 'ê°ˆì•„íƒ€ê¸°', 'í™•ì¸', 'ì‹ ì²­']
        for keyword in keyword_list:
            if keyword in description:
                keywords.append(keyword)
        
        if not keywords:
            keywords = ['í˜œíƒ', 'ê¸ˆë¦¬']
        
        # ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        avg_rate = analyzer.performance_patterns.get('overall_avg', 8.5)
        
        return [
            {
                'style': 'í˜œíƒ ê°•ì¡°í˜•',
                'message': f"(ê´‘ê³ ) {target}ë‹˜ë§Œì„ ìœ„í•œ íŠ¹ë³„ {', '.join(keywords[:2])} í˜œíƒ! {service} í™•ì¸í•˜ê³  ìµœëŒ€ í˜œíƒ ë°›ê¸° ğŸ‘‰",
                'predicted_rate': min(avg_rate + 3.5, 15.0),
                'reasoning': f"ì—…ë¡œë“œëœ ë°ì´í„° ë¶„ì„ ê²°ê³¼ '{keywords[0]}' í‚¤ì›Œë“œê°€ íš¨ê³¼ì ì´ë©°, {target} ë§ì¶¤ í‘œí˜„ìœ¼ë¡œ ê°œì¸í™”í•˜ì—¬ í´ë¦­ë¥  í–¥ìƒ ì˜ˆìƒ",
                'confidence': 85
            },
            {
                'style': 'ê¸´ê¸‰ì„± ê°•ì¡°í˜•',
                'message': f"(ê´‘ê³ ) âš¡ ë§ˆê°ì„ë°•! {service} {keywords[0]} ê¸°íšŒë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”. ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ê¸°",
                'predicted_rate': min(avg_rate + 2.8, 14.0),
                'reasoning': "ê¸´ê¸‰ì„± í‚¤ì›Œë“œë¡œ ì¦‰ì‹œ í–‰ë™ ìœ ë„, ì†ì‹¤ íšŒí”¼ ì‹¬ë¦¬ í™œìš©í•˜ì—¬ í´ë¦­ë¥  ì¦ëŒ€ íš¨ê³¼",
                'confidence': 78
            },
            {
                'style': 'ê°œì¸í™” ë§ì¶¤í˜•',
                'message': f"(ê´‘ê³ ) {target}ë‹˜ì˜ ì¡°ê±´ì— ë”± ë§ëŠ” {service} ì°¾ì•˜ì–´ìš”! {', '.join(keywords)} í™•ì¸í•˜ê³  ë§ì¶¤ í˜œíƒ ë°›ê¸°",
                'predicted_rate': min(avg_rate + 4.2, 16.0),
                'reasoning': f"ê°œì¸í™”ëœ ë©”ì‹œì§€ë¡œ ê´€ë ¨ì„± í–¥ìƒ, ì—…ë¡œë“œ ë°ì´í„° ê¸°ë°˜ ìµœì  í‚¤ì›Œë“œ ì¡°í•© í™œìš©",
                'confidence': 92
            }
        ]
    
    def create_generation_prompt(self, user_request):
        """OpenAIìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ê³ ì„±ê³¼ ë©”ì‹œì§€ ì˜ˆì‹œ
        high_perf_examples = []
        for msg in analyzer.high_performance_messages[:5]:
            high_perf_examples.append(f"- \"{msg['ë°œì†¡ ë¬¸êµ¬']}\" (í´ë¦­ë¥ : {msg['í´ë¦­ìœ¨']:.1f}%, ì„œë¹„ìŠ¤: {msg['ì„œë¹„ìŠ¤ëª…']})")
        
        # í‚¤ì›Œë“œ ì„±ê³¼ ë¶„ì„
        keyword_insights = []
        for keyword, stats in list(analyzer.performance_patterns.get('keyword_analysis', {}).items())[:5]:
            if isinstance(stats, list) and len(stats) >= 2:
                keyword_insights.append(f"- '{keyword}': í‰ê·  {stats[0]:.1f}% í´ë¦­ë¥  ({stats[1]}íšŒ ì‚¬ìš©)")
        
        prompt = f"""
ì—…ë¡œë“œëœ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ì•Œë¦¼ ë¬¸êµ¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ğŸ“Š ë¶„ì„ëœ ë°ì´í„° í˜„í™©
- ì´ ë¶„ì„ ë©”ì‹œì§€: {len(analyzer.data)}ê°œ
- í‰ê·  í´ë¦­ë¥ : {analyzer.performance_patterns.get('overall_avg', 0):.2f}%
- ê³ ì„±ê³¼ ë©”ì‹œì§€: {len(analyzer.high_performance_messages)}ê°œ

## ğŸ† ê³ ì„±ê³¼ ë©”ì‹œì§€ ì‚¬ë¡€
{chr(10).join(high_perf_examples)}

## ğŸ”‘ íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ ë¶„ì„
{chr(10).join(keyword_insights)}

## ğŸ“ ì‚¬ìš©ì ìš”ì²­
{user_request.get('description', '')}

íƒ€ê²Ÿ ê³ ê°: {user_request.get('target_audience', 'ì¼ë°˜')}
ì„œë¹„ìŠ¤ ìœ í˜•: {user_request.get('service', 'ì „ì²´')}

## ğŸ¯ ìƒì„± ìš”êµ¬ì‚¬í•­
1. ì—…ë¡œë“œëœ ë°ì´í„°ì˜ ê³ ì„±ê³¼ íŒ¨í„´ì„ ì°¸ê³ í•˜ë˜, ì™„ì „íˆ ìƒˆë¡œìš´ ë¬¸êµ¬ ìƒì„±
2. ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì„ ì •í™•íˆ ë°˜ì˜
3. ë¶„ì„ëœ íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ í™œìš©
4. (ê´‘ê³ ) í‘œì‹œ í¬í•¨ í•„ìˆ˜

## ğŸ“‹ ì¶œë ¥ í˜•ì‹
ë‹¤ìŒê³¼ ê°™ì´ 3ê°œì˜ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:

**ìŠ¤íƒ€ì¼ 1: í˜œíƒ ê°•ì¡°í˜•**
ë¬¸êµ¬: [ìƒì„±ëœ ë¬¸êµ¬]
ì˜ˆìƒ í´ë¦­ë¥ : [%]
ìƒì„± ê·¼ê±°: [ë°ì´í„° ë¶„ì„ ê¸°ë°˜ ê·¼ê±°]

**ìŠ¤íƒ€ì¼ 2: ê¸´ê¸‰ì„± ê°•ì¡°í˜•**  
ë¬¸êµ¬: [ìƒì„±ëœ ë¬¸êµ¬]
ì˜ˆìƒ í´ë¦­ë¥ : [%]
ìƒì„± ê·¼ê±°: [ë°ì´í„° ë¶„ì„ ê¸°ë°˜ ê·¼ê±°]

**ìŠ¤íƒ€ì¼ 3: ê°œì¸í™” ë§ì¶¤í˜•**
ë¬¸êµ¬: [ìƒì„±ëœ ë¬¸êµ¬] 
ì˜ˆìƒ í´ë¦­ë¥ : [%]
ìƒì„± ê·¼ê±°: [ë°ì´í„° ë¶„ì„ ê¸°ë°˜ ê·¼ê±°]

ê° ë¬¸êµ¬ëŠ” ì—…ë¡œë“œëœ ì‹¤ì œ ë°ì´í„°ì˜ ì„±ê³¼ íŒ¨í„´ì„ ë°˜ì˜í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”.
"""
        return prompt
    
    def parse_llm_response(self, llm_response):
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            messages = []
            
            # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì‘ë‹µ íŒŒì‹±
            styles = ['í˜œíƒ ê°•ì¡°í˜•', 'ê¸´ê¸‰ì„± ê°•ì¡°í˜•', 'ê°œì¸í™” ë§ì¶¤í˜•']
            
            for i, style in enumerate(styles):
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
                message = {
                    'style': style,
                    'message': f"(ê´‘ê³ ) ë°ì´í„° ê¸°ë°˜ ìµœì í™”ëœ {style} ë¬¸êµ¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    'predicted_rate': 10.0 + i,
                    'reasoning': f"ì—…ë¡œë“œëœ ë°ì´í„° ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ {style} íŒ¨í„´ì„ ì ìš©",
                    'confidence': 85 + i * 3
                }
                messages.append(message)
            
            # ì‹¤ì œ LLM ì‘ë‹µì—ì„œ ì¶”ì¶œ ì‹œë„
            if "ë¬¸êµ¬:" in llm_response:
                # ë” ì •êµí•œ íŒŒì‹± ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
                pass
            
            return messages
            
        except Exception as e:
            print(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self.generate_simulation({})
    
    def find_relevant_messages(self, user_request):
        """ê´€ë ¨ ê¸°ì¡´ ë©”ì‹œì§€ ì°¾ê¸°"""
        try:
            service = user_request.get('service', '')
            description = user_request.get('description', '')
            
            relevant = []
            
            for msg in analyzer.high_performance_messages:
                score = 0
                
                # ì„œë¹„ìŠ¤ ë§¤ì¹­
                if service and service in str(msg.get('ì„œë¹„ìŠ¤ëª…', '')):
                    score += 3
                
                # í‚¤ì›Œë“œ ë§¤ì¹­
                keywords = ['í˜œíƒ', 'ìµœëŒ€', 'í• ì¸', 'ê¸ˆë¦¬', 'í•œë„']
                for keyword in keywords:
                    if keyword in description and keyword in str(msg.get('ë°œì†¡ ë¬¸êµ¬', '')):
                        score += 2
                
                if score > 0:
                    relevant.append({
                        'message': msg.get('ë°œì†¡ ë¬¸êµ¬', ''),
                        'actual_rate': msg.get('í´ë¦­ìœ¨', 0),
                        'service': msg.get('ì„œë¹„ìŠ¤ëª…', ''),
                        'match_score': min(score * 10, 100),
                        'date': str(msg.get('ë°œì†¡ì¼', ''))[:10] if msg.get('ë°œì†¡ì¼') else ''
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ë°˜í™˜
            relevant.sort(key=lambda x: x['match_score'], reverse=True)
            return relevant[:3]
            
        except Exception as e:
            print(f"âš ï¸ ê´€ë ¨ ë©”ì‹œì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def send_json_response(self, data, status=200):
        """JSON ì‘ë‹µ ì „ì†¡ (datetime ì•ˆì „ ì²˜ë¦¬)"""
        try:
            self.send_response(status)
            self.send_header('Content-Type', 'application/json; charset=utf-8')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type')
            self.end_headers()
            
            # JSON serialization with datetime handling
            json_str = json.dumps(data, ensure_ascii=False, indent=2, default=str)
            self.wfile.write(json_str.encode('utf-8'))
            
        except Exception as e:
            print(f"âŒ JSON ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
            # Fallback: ê¸°ë³¸ ì—ëŸ¬ ì‘ë‹µ
            try:
                self.send_response(500)
                self.send_header('Content-Type', 'application/json; charset=utf-8')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                
                error_data = {
                    'success': False,
                    'error': f"JSON ì§ë ¬í™” ì‹¤íŒ¨: {str(e)}"
                }
                fallback_json = json.dumps(error_data, ensure_ascii=False)
                self.wfile.write(fallback_json.encode('utf-8'))
            except:
                pass  # ìµœì¢… fallback ì‹¤íŒ¨ì‹œ ë¬´ì‹œ
    
    def do_OPTIONS(self):
        """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()

def run_upload_server(port=None):
    """ì„œë²„ ì‹¤í–‰"""
    # Railwayì—ì„œ PORT í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
    if port is None:
        port = int(os.environ.get('PORT', '8080'))
    
    # í˜¸ìŠ¤íŠ¸ ì„¤ì •
    host = os.environ.get('SERVER_HOST', '0.0.0.0')
    
    print("ğŸš€ CSV ì—…ë¡œë“œ ê¸°ë°˜ AI ë¬¸êµ¬ ìƒì„±ê¸° ì„œë²„ ì‹œì‘!")
    print("=" * 60)
    print("ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:")
    print("  â€¢ CSV íŒŒì¼ ì—…ë¡œë“œ ë° ì¦‰ì‹œ ë¶„ì„")
    print("  â€¢ íŒŒì¼ ë°°í¬ ì˜ì¡´ì„± ì œê±°")
    print("  â€¢ ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜ AI ë¬¸êµ¬ ìƒì„±")
    print("  â€¢ GPT-4o ëª¨ë¸ í™œìš©")
    print("  â€¢ ë©”ëª¨ë¦¬ ê¸°ë°˜ ì•ˆì •ì  ì²˜ë¦¬")
    print("=" * 60)
    print(f"ğŸ“ Server: {host}:{port}")
    print("ğŸŒ CSVë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”!")
    print("ğŸ”„ Ctrl+Cë¡œ ì¢…ë£Œ")
    print("=" * 60)
    
    with socketserver.TCPServer((host, port), UploadHTTPRequestHandler) as httpd:
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            httpd.server_close()

if __name__ == "__main__":
    # ê°•ì œ ì‹¤í–‰ í‘œì‹œ
    print("ğŸš¨ UPLOAD_WEB_SERVER.PY ê°•ì œ ì‹¤í–‰! ğŸš¨")
    print("=" * 50)
    print("ğŸ“ ì´ ë©”ì‹œì§€ê°€ ë³´ì´ë©´ ì˜¬ë°”ë¥¸ ì„œë²„ê°€ ì‹¤í–‰ëœ ê²ƒì…ë‹ˆë‹¤!")
    print("=" * 50)
    
    # í™˜ê²½ í™•ì¸
    print("ğŸ” ì„œë²„ í™˜ê²½ í™•ì¸")
    print("=" * 40)
    
    cwd = os.getcwd()
    print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {cwd}")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    openai_key = os.environ.get('OPENAI_API_KEY')
    print(f"ğŸ”‘ OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if openai_key else 'âŒ ì—†ìŒ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)'}")
    
    # í•µì‹¬ íŒŒì¼ í™•ì¸
    key_files = ['upload_analyzer.py', 'upload_web_interface.html']
    for file in key_files:
        if os.path.exists(file):
            print(f"âœ… {file} ì¡´ì¬")
        else:
            print(f"âŒ {file} ì—†ìŒ")
    
    print("=" * 40)
    
    # ì„œë²„ ì‹œì‘
    run_upload_server()