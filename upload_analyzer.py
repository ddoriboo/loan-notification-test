#!/usr/bin/env python3
"""
CSV ì—…ë¡œë“œ ê¸°ë°˜ ì•Œë¦¼ ë¬¸êµ¬ ë¶„ì„ê¸°
- íŒŒì¼ ë°°í¬ ì˜ì¡´ì„± ì œê±°
- ì‚¬ìš©ìê°€ ì§ì ‘ CSV ì—…ë¡œë“œ
- ë©”ëª¨ë¦¬ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬
"""

import csv
import json
import io
import os
from datetime import datetime
import statistics
import re

class UploadAnalyzer:
    def __init__(self):
        self.data = []
        self.high_performance_messages = []
        self.performance_patterns = {}
        self.analysis_complete = False
        
    def analyze_uploaded_csv(self, csv_content):
        """ì—…ë¡œë“œëœ CSV ë‚´ìš© ë¶„ì„ (ê°•í™”ëœ ë””ë²„ê·¸)"""
        try:
            print("\n" + "="*50)
            print("ğŸ“Š ì—…ë¡œë“œëœ CSV ë¶„ì„ ì‹œì‘...")
            print("="*50)
            print(f"ğŸ“„ CSV ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {csv_content[:200]}...")
            
            # ë°ì´í„° ì™„ì „ ì´ˆê¸°í™” (ê°•ì œ)
            print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì™„ì „ ì‚­ì œ...")
            self.data = []
            self.high_performance_messages = []
            self.performance_patterns = {}
            self.analysis_complete = False
            print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: data={len(self.data)}, patterns={len(self.performance_patterns)}")
            
            # CSV ë¼ì¸ ìˆ˜ í™•ì¸
            lines = csv_content.strip().split('\n')
            print(f"ğŸ“‹ ì´ ë¼ì¸ ìˆ˜: {len(lines)}ê°œ (í—¤ë” í¬í•¨)")
            
            # CSV íŒŒì‹±
            csv_file = io.StringIO(csv_content)
            reader = csv.DictReader(csv_file)
            
            print(f"ğŸ“‹ CSV í—¤ë”: {reader.fieldnames}")
            
            # í–‰ë³„ ì²˜ë¦¬
            processed_count = 0
            for i, row in enumerate(reader):
                try:
                    # í•„ë“œëª… ì •ê·œí™” (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
                    normalized_row = self.normalize_fields(row)
                    
                    # ë°ì´í„° íƒ€ì… ë³€í™˜
                    processed_row = self.process_row(normalized_row)
                    
                    if processed_row:
                        self.data.append(processed_row)
                        processed_count += 1
                        
                        # ì²˜ìŒ 3ê°œ í–‰ ë‚´ìš© í‘œì‹œ
                        if processed_count <= 3:
                            print(f"ğŸ“ í–‰ {processed_count}: {processed_row.get('ì„œë¹„ìŠ¤ëª…', 'N/A')}, {processed_row.get('í´ë¦­ìœ¨', 0)}%, {processed_row.get('ìš”ì¼', 'N/A')}")
                            
                except Exception as e:
                    print(f"âš ï¸ í–‰ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ í–‰ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë¨")
            
            if not self.data:
                raise Exception("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSV í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # ì„±ê³¼ íŒ¨í„´ ë¶„ì„
            self.analyze_patterns()
            
            self.analysis_complete = True
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(self.data)}ê°œ ë©”ì‹œì§€, ê³ ì„±ê³¼ {len(self.high_performance_messages)}ê°œ")
            
            return {
                'success': True,
                'total_messages': len(self.data),
                'high_performance_count': len(self.high_performance_messages),
                'summary': self.get_summary()
            }
            
        except Exception as e:
            print(f"âŒ CSV ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def normalize_fields(self, row):
        """í•„ë“œëª… ì •ê·œí™” (ë‹¤ì–‘í•œ CSV í˜•ì‹ ì§€ì›)"""
        # ê°€ëŠ¥í•œ í•„ë“œëª… ë§¤í•‘
        field_mappings = {
            'í´ë¦­ìœ¨': ['í´ë¦­ìœ¨', 'í´ë¦­ë¥ ', 'CTR', 'click_rate', 'clickrate'],
            'ë°œì†¡ ë¬¸êµ¬': ['ë°œì†¡ ë¬¸êµ¬', 'ë¬¸êµ¬', 'message', 'ë‚´ìš©', 'content', 'ì•Œë¦¼ë‚´ìš©'],
            'ì„œë¹„ìŠ¤ëª…': ['ì„œë¹„ìŠ¤ëª…', 'ì„œë¹„ìŠ¤', 'service', 'service_name', 'ìƒí’ˆëª…'],
            'ë°œì†¡ì¼': ['ë°œì†¡ì¼', 'ë°œì†¡ë‚ ì§œ', 'date', 'send_date', 'ë‚ ì§œ'],
            'ìš”ì¼': ['ìš”ì¼', 'weekday', 'day'],
            'ë°œì†¡íšŒì›ìˆ˜': ['ë°œì†¡íšŒì›ìˆ˜', 'send_count', 'ë°œì†¡ìˆ˜'],
            'í´ë¦­íšŒì›ìˆ˜': ['í´ë¦­íšŒì›ìˆ˜', 'click_count', 'í´ë¦­ìˆ˜']
        }
        
        normalized = {}
        
        for standard_field, possible_names in field_mappings.items():
            for possible_name in possible_names:
                if possible_name in row:
                    normalized[standard_field] = row[possible_name]
                    break
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if standard_field not in normalized:
                if standard_field == 'í´ë¦­ìœ¨':
                    normalized[standard_field] = '0'
                elif standard_field == 'ë°œì†¡ ë¬¸êµ¬':
                    normalized[standard_field] = 'ê¸°ë³¸ ë¬¸êµ¬'
                elif standard_field == 'ì„œë¹„ìŠ¤ëª…':
                    normalized[standard_field] = 'ê¸°íƒ€'
                else:
                    normalized[standard_field] = ''
        
        return normalized
    
    def process_row(self, row):
        """í–‰ ë°ì´í„° ì²˜ë¦¬ ë° íƒ€ì… ë³€í™˜ (JSON serializable)"""
        try:
            processed = {}
            
            # í´ë¦­ë¥  ë³€í™˜
            click_rate_str = str(row.get('í´ë¦­ìœ¨', '0')).strip()
            if click_rate_str.replace('.', '').replace('%', '').isdigit():
                click_rate = float(click_rate_str.replace('%', ''))
                processed['í´ë¦­ìœ¨'] = click_rate if click_rate <= 100 else click_rate / 100
            else:
                processed['í´ë¦­ìœ¨'] = 0.0
            
            # í…ìŠ¤íŠ¸ í•„ë“œ
            processed['ë°œì†¡ ë¬¸êµ¬'] = str(row.get('ë°œì†¡ ë¬¸êµ¬', '')).strip()
            processed['ì„œë¹„ìŠ¤ëª…'] = str(row.get('ì„œë¹„ìŠ¤ëª…', '')).strip()
            
            # ë‚ ì§œ ì²˜ë¦¬ (JSON serializable ë¬¸ìì—´ë¡œ ì €ì¥)
            date_str = str(row.get('ë°œì†¡ì¼', '')).strip()
            if date_str:
                try:
                    # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì§€ì›
                    parsed_date = None
                    for date_format in ['%Y-%m-%d', '%Y.%m.%d', '%Y/%m/%d']:
                        try:
                            parsed_date = datetime.strptime(date_str, date_format)
                            break
                        except ValueError:
                            continue
                    
                    if parsed_date:
                        processed['ë°œì†¡ì¼'] = parsed_date.strftime('%Y-%m-%d')  # ë¬¸ìì—´ë¡œ ì €ì¥
                        processed['ë°œì†¡ì¼_ê°ì²´'] = parsed_date  # ë‚´ë¶€ ê³„ì‚°ìš© (JSONì—ì„œ ì œì™¸)
                    else:
                        processed['ë°œì†¡ì¼'] = datetime.now().strftime('%Y-%m-%d')
                        processed['ë°œì†¡ì¼_ê°ì²´'] = datetime.now()
                except:
                    processed['ë°œì†¡ì¼'] = datetime.now().strftime('%Y-%m-%d')
                    processed['ë°œì†¡ì¼_ê°ì²´'] = datetime.now()
            else:
                processed['ë°œì†¡ì¼'] = datetime.now().strftime('%Y-%m-%d')
                processed['ë°œì†¡ì¼_ê°ì²´'] = datetime.now()
            
            # ìš”ì¼ ì²˜ë¦¬
            weekday = str(row.get('ìš”ì¼', '')).strip()
            if not weekday:
                weekday_num = processed['ë°œì†¡ì¼_ê°ì²´'].weekday()
                weekdays = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
                weekday = weekdays[weekday_num]
            processed['ìš”ì¼'] = weekday
            
            # ìˆ«ì í•„ë“œë“¤
            processed['ë°œì†¡íšŒì›ìˆ˜'] = self.safe_int(row.get('ë°œì†¡íšŒì›ìˆ˜', '0'))
            processed['í´ë¦­íšŒì›ìˆ˜'] = self.safe_int(row.get('í´ë¦­íšŒì›ìˆ˜', '0'))
            
            return processed
            
        except Exception as e:
            print(f"âš ï¸ í–‰ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def safe_int(self, value):
        """ì•ˆì „í•œ ì •ìˆ˜ ë³€í™˜"""
        try:
            return int(float(str(value).replace(',', '')))
        except:
            return 0
    
    def analyze_patterns(self):
        """ì„±ê³¼ íŒ¨í„´ ë¶„ì„"""
        try:
            # ê³ ì„±ê³¼ ë©”ì‹œì§€ ê¸°ì¤€ ë™ì  ê³„ì‚°
            all_rates = [row.get('í´ë¦­ìœ¨', 0) for row in self.data if row.get('í´ë¦­ìœ¨', 0) > 0]
            if all_rates:
                avg_rate = sum(all_rates) / len(all_rates)
                high_performance_threshold = max(avg_rate * 1.2, 8.0)  # í‰ê· ì˜ 120% ë˜ëŠ” ìµœì†Œ 8%
                print(f"ğŸ“ˆ ê³ ì„±ê³¼ ê¸°ì¤€: {high_performance_threshold:.1f}% (í‰ê· : {avg_rate:.1f}%)")
                
                # ê³ ì„±ê³¼ ë©”ì‹œì§€ ìˆ˜ì§‘ (ìƒìœ„ 20% ë˜ëŠ” ê¸°ì¤€ ì´ìƒ)
                sorted_data = sorted(self.data, key=lambda x: x.get('í´ë¦­ìœ¨', 0), reverse=True)
                top_20_percent = max(len(sorted_data) // 5, 10)  # ìƒìœ„ 20% ë˜ëŠ” ìµœì†Œ 10ê°œ
                
                self.high_performance_messages = []
                for row in sorted_data[:top_20_percent]:
                    if row.get('í´ë¦­ìœ¨', 0) >= high_performance_threshold:
                        self.high_performance_messages.append(row)
                
                # ê³ ì„±ê³¼ ê¸°ì¤€ ì •ì˜ ì €ì¥
                self.high_performance_criteria = {
                    'threshold_rate': high_performance_threshold,
                    'avg_rate': avg_rate,
                    'description': f"í‰ê·  í´ë¦­ë¥ ({avg_rate:.1f}%)ì˜ 120% ì´ìƒ ë˜ëŠ” ìµœì†Œ 8% ì´ìƒ",
                    'count': len(self.high_performance_messages),
                    'top_percent': 20,
                    'total_candidates': top_20_percent
                }
                
                # ë™ì¼ ë¬¸êµ¬ ì§‘ê³„ ì²˜ë¦¬
                self.aggregated_high_performance = self.aggregate_high_performance_messages()
                
                print(f"âœ… ê³ ì„±ê³¼ ë©”ì‹œì§€: {len(self.high_performance_messages)}ê°œ (ìµœê³ : {sorted_data[0].get('í´ë¦­ìœ¨', 0):.1f}%), ì§‘ê³„ëœ ë¬¸êµ¬: {len(self.aggregated_high_performance)}ê°œ")
            
            # ì„œë¹„ìŠ¤ë³„ ë¶„ì„ (JSON serializable)
            service_analysis = {}
            for row in self.data:
                service = row.get('ì„œë¹„ìŠ¤ëª…', 'ê¸°íƒ€')
                if service not in service_analysis:
                    service_analysis[service] = {
                        'messages': [],
                        'total_clicks': 0,
                        'count': 0
                    }
                
                # datetime ê°ì²´ ì œì™¸í•œ ì •ë¦¬ëœ ë©”ì‹œì§€ ë°ì´í„° ì¶”ê°€
                clean_row = {}
                for key, value in row.items():
                    if key == 'ë°œì†¡ì¼_ê°ì²´':
                        continue  # ë‚´ë¶€ ê³„ì‚°ìš© ê°ì²´ ì œì™¸
                    elif isinstance(value, (int, float, str, bool)) or value is None:
                        clean_row[key] = value
                    else:
                        clean_row[key] = str(value)
                
                service_analysis[service]['messages'].append(clean_row)
                service_analysis[service]['total_clicks'] += row.get('í´ë¦­ìœ¨', 0)
                service_analysis[service]['count'] += 1
            
            # ì„œë¹„ìŠ¤ë³„ í‰ê·  ê³„ì‚°
            for service in service_analysis:
                count = service_analysis[service]['count']
                total = service_analysis[service]['total_clicks']
                service_analysis[service]['avg_click_rate'] = total / count if count > 0 else 0
                
                # ìƒìœ„ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì•ˆì „í•œ ì •ë ¬)
                try:
                    service_analysis[service]['messages'].sort(
                        key=lambda x: float(x.get('í´ë¦­ìœ¨', 0)), reverse=True
                    )
                    service_analysis[service]['messages'] = service_analysis[service]['messages'][:5]
                except Exception as e:
                    print(f"âš ï¸ ì„œë¹„ìŠ¤ {service} ë©”ì‹œì§€ ì •ë ¬ ì‹¤íŒ¨: {e}")
                    service_analysis[service]['messages'] = service_analysis[service]['messages'][:5]
            
            # í‚¤ì›Œë“œ ë¶„ì„
            keywords = ['í˜œíƒ', 'ìµœëŒ€', 'í• ì¸', 'ê¸ˆë¦¬', 'í•œë„', 'ëŒ€ì¶œ', 'ë¹„êµ', 'ê°ˆì•„íƒ€ê¸°', 'í™•ì¸', 'ì‹ ì²­']
            keyword_performance = {}
            
            for keyword in keywords:
                keyword_messages = [
                    row for row in self.data 
                    if keyword in str(row.get('ë°œì†¡ ë¬¸êµ¬', ''))
                ]
                
                if keyword_messages:
                    rates = [row.get('í´ë¦­ìœ¨', 0) for row in keyword_messages]
                    avg_rate = sum(rates) / len(rates) if rates else 0
                    keyword_performance[keyword] = [avg_rate, len(keyword_messages)]
            
            # ìš”ì¼ë³„ ë¶„ì„
            weekday_analysis = {}
            weekdays = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
            
            for day in weekdays:
                day_messages = [row for row in self.data if row.get('ìš”ì¼') == day]
                if day_messages:
                    rates = [row.get('í´ë¦­ìœ¨', 0) for row in day_messages]
                    avg_rate = sum(rates) / len(rates) if rates else 0
                    weekday_analysis[day] = {
                        'avg_click_rate': avg_rate,
                        'count': len(day_messages)
                    }
                else:
                    weekday_analysis[day] = {'avg_click_rate': 0, 'count': 0}
            
            # ì „ì²´ í†µê³„
            all_rates = [row.get('í´ë¦­ìœ¨', 0) for row in self.data]
            overall_avg = sum(all_rates) / len(all_rates) if all_rates else 0
            best_rate = max(all_rates) if all_rates else 0
            
            self.performance_patterns = {
                'service_analysis': service_analysis,
                'keyword_analysis': keyword_performance,
                'time_analysis': weekday_analysis,
                'overall_avg': overall_avg,
                'best_click_rate': best_rate,
                'high_performance_criteria': getattr(self, 'high_performance_criteria', {})
            }
            
        except Exception as e:
            print(f"âŒ íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ íŒ¨í„´ ì„¤ì •
            self.performance_patterns = {
                'service_analysis': {},
                'keyword_analysis': {},
                'time_analysis': {},
                'overall_avg': 0,
                'best_click_rate': 0
            }
    
    def get_dashboard_data(self):
        """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° ë°˜í™˜ (JSON serializable)"""
        if not self.analysis_complete:
            return {
                'success': False,
                'error': 'ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.'
            }
        
        # JSON serializable í˜•íƒœë¡œ ë³€í™˜
        clean_high_performance = []
        for msg in self.high_performance_messages[:10]:
            clean_msg = {}
            for key, value in msg.items():
                # datetime ê°ì²´ ì œì™¸ ë° ì•ˆì „í•œ ë³€í™˜
                if key == 'ë°œì†¡ì¼_ê°ì²´':
                    continue  # ë‚´ë¶€ ê³„ì‚°ìš© ê°ì²´ ì œì™¸
                elif key == 'ë°œì†¡ì¼' and hasattr(value, 'strftime'):
                    clean_msg[key] = value.strftime('%Y-%m-%d')
                elif isinstance(value, (int, float, str, bool)) or value is None:
                    clean_msg[key] = value
                else:
                    # ê¸°íƒ€ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                    clean_msg[key] = str(value)
            clean_high_performance.append(clean_msg)
        
        # ì„œë¹„ìŠ¤ ë¶„ì„ ë°ì´í„° ì •ë¦¬
        clean_service_analysis = {}
        service_analysis = self.performance_patterns.get('service_analysis', {})
        for service, data in service_analysis.items():
            clean_service_data = {
                'count': data.get('count', 0),
                'avg_click_rate': data.get('avg_click_rate', 0),
                'messages': []
            }
            
            # ë©”ì‹œì§€ ë°ì´í„° ì •ë¦¬
            for msg in data.get('messages', []):
                clean_msg = {}
                for key, value in msg.items():
                    if key == 'ë°œì†¡ì¼_ê°ì²´':
                        continue
                    elif isinstance(value, (int, float, str, bool)) or value is None:
                        clean_msg[key] = value
                    else:
                        clean_msg[key] = str(value)
                clean_service_data['messages'].append(clean_msg)
            
            clean_service_analysis[service] = clean_service_data
        
        return {
            'success': True,
            'data': {
                'summary': {
                    'total_messages': len(self.data),
                    'avg_click_rate': self.performance_patterns.get('overall_avg', 0),
                    'best_click_rate': self.performance_patterns.get('best_click_rate', 0),
                    'high_performance_count': len(self.high_performance_messages),
                    'high_performance_criteria': self.performance_patterns.get('high_performance_criteria', {})
                },
                'service_analysis': clean_service_analysis,
                'keyword_analysis': self.performance_patterns.get('keyword_analysis', {}),
                'time_analysis': self.performance_patterns.get('time_analysis', {}),
                'high_performance_messages': clean_high_performance,
                'aggregated_high_performance': getattr(self, 'aggregated_high_performance', [])
            }
        }
    
    def get_summary(self):
        """ë¶„ì„ ìš”ì•½ ì •ë³´"""
        if not self.data:
            return {}
        
        all_rates = [row.get('í´ë¦­ìœ¨', 0) for row in self.data]
        
        return {
            'total_messages': len(self.data),
            'avg_click_rate': sum(all_rates) / len(all_rates) if all_rates else 0,
            'max_click_rate': max(all_rates) if all_rates else 0,
            'min_click_rate': min(all_rates) if all_rates else 0,
            'high_performance_count': len(self.high_performance_messages),
            'services_count': len(set(row.get('ì„œë¹„ìŠ¤ëª…', '') for row in self.data))
        }
    
    def aggregate_high_performance_messages(self):
        """ë™ì¼ ë¬¸êµ¬ì˜ ê³ ì„±ê³¼ ë©”ì‹œì§€ ì§‘ê³„"""
        try:
            if not self.high_performance_messages:
                return []
            
            # ë¬¸êµ¬ë³„ ê·¸ë£¹í™”
            message_groups = {}
            
            for msg in self.high_performance_messages:
                message_text = str(msg.get('ë°œì†¡ ë¬¸êµ¬', '')).strip()
                
                # ë™ì¼ ë¬¸êµ¬ ê·¸ë£¹í™”
                if message_text not in message_groups:
                    message_groups[message_text] = {
                        'message': message_text,
                        'occurrences': [],
                        'total_sends': 0,
                        'total_clicks': 0,
                        'click_rates': [],
                        'services': set(),
                        'dates': []
                    }
                
                group = message_groups[message_text]
                group['occurrences'].append(msg)
                group['total_sends'] += msg.get('ë°œì†¡íšŒì›ìˆ˜', 0)
                
                # í´ë¦­ ìˆ˜ ê³„ì‚° (í´ë¦­ë¥  * ë°œì†¡ìˆ˜)
                click_rate = msg.get('í´ë¦­ìœ¨', 0)
                send_count = msg.get('ë°œì†¡íšŒì›ìˆ˜', 0)
                clicks = int((click_rate / 100) * send_count) if send_count > 0 else 0
                group['total_clicks'] += clicks
                
                group['click_rates'].append(click_rate)
                group['services'].add(msg.get('ì„œë¹„ìŠ¤ëª…', 'ê¸°íƒ€'))
                group['dates'].append(msg.get('ë°œì†¡ì¼', ''))
            
            # ì§‘ê³„ ê²°ê³¼ ê³„ì‚°
            aggregated_results = []
            for message_text, group in message_groups.items():
                # í‰ê·  í´ë¦­ë¥  ê³„ì‚°
                avg_click_rate = sum(group['click_rates']) / len(group['click_rates']) if group['click_rates'] else 0
                
                # ìµœê³ /ìµœì € í´ë¦­ë¥ 
                max_click_rate = max(group['click_rates']) if group['click_rates'] else 0
                min_click_rate = min(group['click_rates']) if group['click_rates'] else 0
                
                # ì´ í´ë¦­ë¥  (ì „ì²´ í´ë¦­ìˆ˜ / ì „ì²´ ë°œì†¡ìˆ˜)
                total_click_rate = (group['total_clicks'] / group['total_sends'] * 100) if group['total_sends'] > 0 else 0
                
                aggregated_results.append({
                    'message': message_text,
                    'send_count': len(group['occurrences']),  # ë°œì†¡ íšŸìˆ˜
                    'total_sends': group['total_sends'],      # ì´ ë°œì†¡ íšŒì›ìˆ˜
                    'total_clicks': group['total_clicks'],   # ì´ í´ë¦­ ìˆ˜
                    'avg_click_rate': round(avg_click_rate, 2),
                    'max_click_rate': round(max_click_rate, 2),
                    'min_click_rate': round(min_click_rate, 2),
                    'total_click_rate': round(total_click_rate, 2),  # ì „ì²´ ê¸°ì¤€ í´ë¦­ë¥ 
                    'services': list(group['services']),
                    'date_range': {
                        'first': min(group['dates']) if group['dates'] else '',
                        'last': max(group['dates']) if group['dates'] else ''
                    },
                    'occurrences': group['occurrences']
                })
            
            # ì „ì²´ í´ë¦­ë¥  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            aggregated_results.sort(key=lambda x: x['total_click_rate'], reverse=True)
            
            print(f"ğŸ“Š ê³ ì„±ê³¼ ë©”ì‹œì§€ ì§‘ê³„ ì™„ë£Œ: {len(message_groups)}ê°œ ê³ ìœ  ë¬¸êµ¬")
            return aggregated_results
            
        except Exception as e:
            print(f"âŒ ê³ ì„±ê³¼ ë©”ì‹œì§€ ì§‘ê³„ ì‹¤íŒ¨: {e}")
            return []
    
    def generate_natural_language_insights(self):
        """ìì—°ì–´ ê¸°ë°˜ CSV ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not self.analysis_complete or not self.data:
                return {
                    'success': False,
                    'error': 'ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
                }
            
            insights = []
            
            # 1. ì „ì²´ ì„±ê³¼ ê°œìš”
            total_messages = len(self.data)
            avg_rate = self.performance_patterns.get('overall_avg', 0)
            best_rate = self.performance_patterns.get('best_click_rate', 0)
            high_perf_count = len(self.high_performance_messages)
            
            insights.append({
                'category': 'ğŸ“Š ì „ì²´ ì„±ê³¼ ê°œìš”',
                'content': f"ì´ {total_messages}ê°œì˜ ì•Œë¦¼ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•œ ê²°ê³¼, í‰ê·  í´ë¦­ë¥ ì€ {avg_rate:.1f}%ì´ë©° ìµœê³  ì„±ê³¼ëŠ” {best_rate:.1f}%ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ë©”ì‹œì§€ ì¤‘ {high_perf_count}ê°œ({(high_perf_count/total_messages*100):.1f}%)ê°€ ê³ ì„±ê³¼ ë©”ì‹œì§€ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤."
            })
            
            # 2. ì„œë¹„ìŠ¤ë³„ ì„±ê³¼ ë¶„ì„
            service_analysis = self.performance_patterns.get('service_analysis', {})
            if service_analysis:
                best_service = max(service_analysis.items(), key=lambda x: x[1].get('avg_click_rate', 0))
                worst_service = min(service_analysis.items(), key=lambda x: x[1].get('avg_click_rate', 0))
                
                insights.append({
                    'category': 'ğŸ·ï¸ ì„œë¹„ìŠ¤ë³„ ì„±ê³¼',
                    'content': f"ì„œë¹„ìŠ¤ë³„ ë¶„ì„ ê²°ê³¼, '{best_service[0]}' ì„œë¹„ìŠ¤ê°€ í‰ê·  {best_service[1]['avg_click_rate']:.1f}%ë¡œ ê°€ì¥ ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ê³ , '{worst_service[0]}' ì„œë¹„ìŠ¤ëŠ” {worst_service[1]['avg_click_rate']:.1f}%ë¡œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ {len(service_analysis)}ê°œ ì„œë¹„ìŠ¤ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤."
                })
            
            # 3. í‚¤ì›Œë“œ íš¨ê³¼ ë¶„ì„
            keyword_analysis = self.performance_patterns.get('keyword_analysis', {})
            if keyword_analysis:
                effective_keywords = [(k, v[0]) for k, v in keyword_analysis.items() if isinstance(v, list) and v[0] > avg_rate]
                effective_keywords.sort(key=lambda x: x[1], reverse=True)
                
                if effective_keywords:
                    top_3_keywords = effective_keywords[:3]
                    keyword_text = ", ".join([f"'{k}' ({r:.1f}%)" for k, r in top_3_keywords])
                    insights.append({
                        'category': 'ğŸ”‘ íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ',
                        'content': f"í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼, {keyword_text} ìˆœìœ¼ë¡œ ë†’ì€ í´ë¦­ë¥ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í‚¤ì›Œë“œë“¤ì„ í™œìš©í•˜ë©´ ë©”ì‹œì§€ ì„±ê³¼ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    })
            
            # 4. ì‹œê°„ëŒ€ë³„ ì„±ê³¼
            time_analysis = self.performance_patterns.get('time_analysis', {})
            if time_analysis:
                weekday_performance = [(day, data.get('avg_click_rate', 0)) for day, data in time_analysis.items() if data.get('count', 0) > 0]
                weekday_performance.sort(key=lambda x: x[1], reverse=True)
                
                if weekday_performance:
                    best_day = weekday_performance[0]
                    worst_day = weekday_performance[-1]
                    insights.append({
                        'category': 'ğŸ“… ìš”ì¼ë³„ ì„±ê³¼',
                        'content': f"ìš”ì¼ë³„ ë¶„ì„ì—ì„œëŠ” {best_day[0]}ìš”ì¼ì´ í‰ê·  {best_day[1]:.1f}%ë¡œ ê°€ì¥ íš¨ê³¼ì ì´ì—ˆê³ , {worst_day[0]}ìš”ì¼ì´ {worst_day[1]:.1f}%ë¡œ ê°€ì¥ ë‚®ì•˜ìŠµë‹ˆë‹¤. ë°œì†¡ ì‹œì  ìµœì í™”ë¥¼ í†µí•´ ì„±ê³¼ ê°œì„ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                    })
            
            # 5. ê³ ì„±ê³¼ ë©”ì‹œì§€ íŒ¨í„´ ë¶„ì„
            if self.aggregated_high_performance:
                top_message = self.aggregated_high_performance[0]
                repeated_messages = [msg for msg in self.aggregated_high_performance if msg['send_count'] > 1]
                
                insights.append({
                    'category': 'ğŸ† ê³ ì„±ê³¼ ë©”ì‹œì§€ íŒ¨í„´',
                    'content': f"ìµœê³  ì„±ê³¼ ë©”ì‹œì§€ëŠ” '{top_message['message'][:30]}...'ë¡œ {top_message['total_click_rate']:.1f}%ì˜ í´ë¦­ë¥ ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. {len(repeated_messages)}ê°œì˜ ë©”ì‹œì§€ê°€ ì—¬ëŸ¬ ë²ˆ ë°œì†¡ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ê²€ì¦ëœ íš¨ê³¼ì ì¸ ë¬¸êµ¬ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
                })
            
            # 6. ê°œì„  ì œì•ˆ
            improvement_suggestions = []
            
            # í‰ê· ë³´ë‹¤ ë‚®ì€ ì„œë¹„ìŠ¤ ì‹ë³„
            if service_analysis:
                underperforming_services = [name for name, data in service_analysis.items() if data.get('avg_click_rate', 0) < avg_rate]
                if underperforming_services:
                    improvement_suggestions.append(f"{', '.join(underperforming_services)} ì„œë¹„ìŠ¤ì˜ ë©”ì‹œì§€ ìµœì í™”")
            
            # íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ í™œìš©ë„ ë‚®ì€ ê²½ìš°
            if keyword_analysis and effective_keywords:
                low_usage_keywords = [k for k, v in keyword_analysis.items() if isinstance(v, list) and v[0] > avg_rate and v[1] < 3]
                if low_usage_keywords:
                    improvement_suggestions.append(f"ê³ íš¨ê³¼ í‚¤ì›Œë“œ({', '.join(low_usage_keywords[:2])}) í™œìš©ë„ ì¦ëŒ€")
            
            if improvement_suggestions:
                insights.append({
                    'category': 'ğŸ’¡ ê°œì„  ì œì•ˆ',
                    'content': f"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤: {' / '.join(improvement_suggestions)}. ì´ë¥¼ í†µí•´ ì „ì²´ í‰ê·  í´ë¦­ë¥ ì„ {avg_rate:.1f}%ì—ì„œ {(avg_rate * 1.2):.1f}%ê¹Œì§€ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
                })
            
            return {
                'success': True,
                'insights': insights,
                'summary': {
                    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'data_points': total_messages,
                    'insight_count': len(insights)
                }
            }
            
        except Exception as e:
            print(f"âŒ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = UploadAnalyzer()