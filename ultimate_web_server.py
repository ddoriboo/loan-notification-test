#!/usr/bin/env python3
"""
Ultimate AI ë¬¸êµ¬ ìƒì„±ê¸° í†µí•© ì›¹ ì„œë²„
- ì§„ì§œ LLM ì—°ë™
- íƒ€ì´ë° ìµœì í™”
- ì„±ê³¼ ë¹„êµ ë¶„ì„
"""

import http.server
import socketserver
import json
import urllib.parse
import os
from real_llm_generator import RealLLMGenerator
from enhanced_timing_analyzer import EnhancedTimingAnalyzer

class UltimateHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        # Use current directory instead of hardcoded path
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        if self.path == '/':
            self.path = '/ultimate_ai_message_generator_v2.html'
        return super().do_GET()
    
    def do_POST(self):
        if self.path == '/api/generate':
            self.handle_generate_api()
        elif self.path == '/api/timing':
            self.handle_timing_api()
        elif self.path == '/api/compare':
            self.handle_compare_api()
        elif self.path == '/api/dashboard':
            self.handle_dashboard_api()
        else:
            self.send_error(404)
    
    def handle_generate_api(self):
        """ë¬¸êµ¬ ìƒì„± API"""
        try:
            # ìš”ì²­ ë°ì´í„° ì½ê¸°
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            # ìƒì„±ê¸° ì´ˆê¸°í™” (ì²« ìš”ì²­ ì‹œ)
            if not hasattr(self.server, 'llm_generator'):
                print("ğŸš€ Ultimate AI ìƒì„±ê¸° ì´ˆê¸°í™” ì¤‘...")
                self.server.llm_generator = RealLLMGenerator(
                    "202507_.csv"
                )
                print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
            
            generator = self.server.llm_generator
            
            # ì‚¬ìš©ì ìš”ì²­ êµ¬ì„±
            user_request = {
                'description': data.get('description', ''),
                'service': data.get('service', ''),
                'tone': data.get('tone', 'promotional'),
                'keywords': data.get('keywords', []),
                'target_audience': data.get('target', 'ê³ ê°')
            }
            
            print(f"ğŸ“ ìƒì„± ìš”ì²­: {user_request}")
            
            # LLM ìƒì„±
            llm_result = generator.generate_with_llm(user_request)
            
            # ê¸°ì¡´ ë©”ì‹œì§€ ë§¤ì¹­
            existing_matches = generator.get_relevant_high_performance_messages(user_request)
            
            # ì„±ê³¼ ë¹„êµ
            comparison = generator.compare_with_existing(user_request)
            
            # ì‘ë‹µ êµ¬ì„±
            response = {
                'success': True,
                'timing': llm_result['optimal_timing'],
                'llm_generated': llm_result['generated_messages'],
                'existing_matched': [
                    {
                        'message': msg['ë°œì†¡ ë¬¸êµ¬'],
                        'actual_rate': msg['í´ë¦­ìœ¨'],
                        'service': msg['ì„œë¹„ìŠ¤ëª…'],
                        'match_score': msg.get('relevance_score', 0) * 10,  # 0-100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
                        'reasons': ['í‚¤ì›Œë“œ ë§¤ì¹­', 'í†¤ì•¤ë§¤ë„ˆ ì¼ì¹˜', 'ê³ ì„±ê³¼ ë©”ì‹œì§€']
                    }
                    for msg in existing_matches[:3]
                ],
                'comparison': {
                    'llm_average': sum(msg['predicted_rate'] for msg in llm_result['generated_messages']) / len(llm_result['generated_messages']),
                    'existing_average': sum(msg['í´ë¦­ìœ¨'] for msg in existing_matches[:3]) / len(existing_matches[:3]) if existing_matches else 0,
                    'winner': 'existing' if existing_matches else 'llm',
                    'advantage': 2.5,  # ì„ì‹œê°’
                    'insights': [
                        'LLMì€ ì°½ì˜ì„±ê³¼ ê°œì¸í™”ì—ì„œ ìš°ìˆ˜',
                        'ê¸°ì¡´ ë©”ì‹œì§€ëŠ” ì‹¤ì œ ê²€ì¦ëœ ì„±ê³¼',
                        'í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ì´ ìµœì '
                    ]
                },
                'data_insights': llm_result['data_insights']
            }
            
            # HTTP ì‘ë‹µ
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type')
            self.end_headers()
            
            self.wfile.write(json.dumps(response, ensure_ascii=False, indent=2).encode('utf-8'))
            
        except Exception as e:
            print(f"âŒ ìƒì„± API ì˜¤ë¥˜: {str(e)}")
            self.send_error_response(str(e))
    
    def handle_timing_api(self):
        """íƒ€ì´ë° ë¶„ì„ API"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            # íƒ€ì´ë° ë¶„ì„ê¸° ì´ˆê¸°í™”
            if not hasattr(self.server, 'timing_analyzer'):
                self.server.timing_analyzer = EnhancedTimingAnalyzer(
                    "202507_.csv"
                )
            
            analyzer = self.server.timing_analyzer
            
            # ì„œë¹„ìŠ¤ë³„ ìµœì  íƒ€ì´ë° ë¶„ì„
            service = data.get('service', 'ì „ì²´')
            recommendations = analyzer.get_optimal_timing_recommendation(target_service=service)
            
            response = {
                'success': True,
                'timing_analysis': recommendations,
                'detailed_patterns': {
                    'monthly': {'ì›”ì´ˆ': 8.96, 'ì›”ì¤‘': 7.72, 'ì›”ë§': 8.71},
                    'weekday': {'ì›”': 7.52, 'í™”': 8.82, 'ìˆ˜': 8.88, 'ëª©': 8.30, 'ê¸ˆ': 8.78},
                    'payday': {'ê¸‰ì—¬ì „': 8.96, 'ê¸‰ì—¬ì¼': 8.45, 'ê¸‰ì—¬í›„': 9.41}
                }
            }
            
            self.send_json_response(response)
            
        except Exception as e:
            print(f"âŒ íƒ€ì´ë° API ì˜¤ë¥˜: {str(e)}")
            self.send_error_response(str(e))
    
    def handle_compare_api(self):
        """ì„±ê³¼ ë¹„êµ API"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            # ë¹„êµí•  ë©”ì‹œì§€ë“¤
            llm_messages = data.get('llm_messages', [])
            existing_messages = data.get('existing_messages', [])
            
            # ì„±ê³¼ ë¹„êµ ë¶„ì„
            comparison_result = self.analyze_performance_comparison(llm_messages, existing_messages)
            
            response = {
                'success': True,
                'comparison': comparison_result
            }
            
            self.send_json_response(response)
            
        except Exception as e:
            print(f"âŒ ë¹„êµ API ì˜¤ë¥˜: {str(e)}")
            self.send_error_response(str(e))
    
    def analyze_performance_comparison(self, llm_messages, existing_messages):
        """ì„±ê³¼ ë¹„êµ ë¶„ì„"""
        llm_avg = sum(msg.get('predicted_rate', 0) for msg in llm_messages) / len(llm_messages) if llm_messages else 0
        existing_avg = sum(msg.get('actual_rate', 0) for msg in existing_messages) / len(existing_messages) if existing_messages else 0
        
        winner = 'existing' if existing_avg > llm_avg else 'llm'
        advantage = abs(existing_avg - llm_avg)
        
        insights = []
        if winner == 'existing':
            insights.extend([
                'ê¸°ì¡´ ë©”ì‹œì§€ëŠ” ì‹¤ì œ ì‹œì¥ì—ì„œ ê²€ì¦ëœ ì„±ê³¼',
                'ì‹¤ì œ ê³ ê° ë°˜ì‘ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹ ë¢°ì„±',
                'ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê²€ì¦ëœ íŒ¨í„´'
            ])
        else:
            insights.extend([
                'LLM ìƒì„± ë©”ì‹œì§€ëŠ” ì°½ì˜ì„±ê³¼ ê°œì¸í™”ì—ì„œ ìš°ìˆ˜',
                'ìµœì‹  íŠ¸ë Œë“œì™€ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ë°˜ì˜',
                'ë¬´í•œí•œ ë³€í˜• ê°€ëŠ¥ì„±'
            ])
        
        # ê³µí†µ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        insights.append('í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼(ê¸°ì¡´ íŒ¨í„´ + LLM ì°½ì˜ì„±)ì´ ìµœì ')
        
        return {
            'llm_average': round(llm_avg, 1),
            'existing_average': round(existing_avg, 1),
            'winner': winner,
            'advantage': round(advantage, 1),
            'insights': insights,
            'recommendation': 'ê¸°ì¡´ ê³ ì„±ê³¼ íŒ¨í„´ì„ ë² ì´ìŠ¤ë¡œ LLMì˜ ì°½ì˜ì„±ì„ ê²°í•©í•˜ëŠ” ê²ƒì´ ìµœì '
        }
    
    def handle_dashboard_api(self):
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° API"""
        try:
            # ìƒì„±ê¸° ì´ˆê¸°í™” í™•ì¸
            if not hasattr(self.server, 'llm_generator'):
                print("ğŸš€ Ultimate AI ìƒì„±ê¸° ì´ˆê¸°í™” ì¤‘...")
                self.server.llm_generator = RealLLMGenerator(
                    "202507_.csv"
                )
                print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
            
            generator = self.server.llm_generator
            
            # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            dashboard_data = generator.get_dashboard_data()
            
            # ì„±ê³µ ì‘ë‹µ
            response = {
                'success': True,
                'data': dashboard_data
            }
            
            self.send_json_response(response)
            
        except Exception as e:
            self.send_error_response(str(e))
    
    def send_json_response(self, data):
        """JSON ì‘ë‹µ ì „ì†¡"""
        self.send_response(200)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()
        
        self.wfile.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def send_error_response(self, error_message):
        """ì—ëŸ¬ ì‘ë‹µ ì „ì†¡"""
        error_response = {
            'success': False,
            'error': error_message
        }
        
        self.send_response(500)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        self.wfile.write(json.dumps(error_response, ensure_ascii=False).encode('utf-8'))
    
    def do_OPTIONS(self):
        """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()

def run_ultimate_server(port=None):
    """Ultimate ì„œë²„ ì‹¤í–‰"""
    # Railway sets PORT environment variable
    if port is None:
        port = int(os.environ.get('PORT', '8080'))
    
    # Get host from environment or use default
    host = os.environ.get('SERVER_HOST', '0.0.0.0')
    
    print("ğŸš€ Ultimate AI ë¬¸êµ¬ ìƒì„±ê¸° ì„œë²„ ì‹œì‘!")
    print("="*60)
    print("ğŸ¯ í†µí•© ê¸°ëŠ¥:")
    print("  â€¢ ì§„ì§œ LLM ê¸°ë°˜ ë¬¸êµ¬ ìƒì„±")
    print("  â€¢ 18ê°œì›” ì‹¤ì œ ë°ì´í„° í•™ìŠµ")
    print("  â€¢ íƒ€ì´ë° ìµœì í™” (ì›”ì´ˆ+ìˆ˜ìš”ì¼)")
    print("  â€¢ ì„±ê³¼ ë¹„êµ ë¶„ì„")
    print("  â€¢ ì‹¤ì‹œê°„ ìƒì„± ê·¼ê±° ì„¤ëª…")
    print("="*60)
    print(f"ğŸ“ Server: {host}:{port}")
    print("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•˜ì„¸ìš”!")
    print("ğŸ”„ Ctrl+Cë¡œ ì¢…ë£Œ")
    print("="*60)
    
    with socketserver.TCPServer((host, port), UltimateHTTPRequestHandler) as httpd:
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Ultimate AI ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            httpd.server_close()

if __name__ == "__main__":
    # ì„œë²„ ì‹œì‘
    run_ultimate_server()